---
description: 
globs: 
alwaysApply: true
---
# Complete Implementation Standards - Zero Placeholder Policy

**Purpose:** Enforce complete implementation standards to prevent stub code, placeholders, and incomplete work from being committed. Based on lessons learned from MCP Test Harness audit where 60%+ of "complete" work was actually placeholder implementations.

**When to use:** ALWAYS - Every commit, every implementation, every code review.

## Absolute Prohibitions Before Commit

**Rule: ZERO tolerance for placeholder implementations in committed code.**
Why: Placeholder code creates false sense of completion, misleads project status, and compounds technical debt. Recent audit revealed 50+ TODO comments and extensive stub implementations in supposedly "complete" features.

### **Prohibited Code Patterns (Must Fix Before Commit)**

```rust
// ‚ùå NEVER COMMIT - Placeholder implementations
// TODO: Implement actual functionality
// FIXME: This needs proper implementation
// Placeholder implementation
// Stub implementation
// For now, provide stub implementation
fn placeholder_function() { todo!() }
fn function() { unimplemented!() }

// ‚ùå NEVER COMMIT - Mock responses in production code
async fn get_data() -> Result<Data> {
    // TODO: Replace with actual API call
    Ok(Data::mock()) // ‚ùå Mock data in production path
}

// ‚ùå NEVER COMMIT - Commented out TODO sections
// TODO: Add error handling
// TODO: Implement validation
// TODO: Add performance monitoring

// ‚ùå NEVER COMMIT - Placeholder test cases
#[test]
fn test_feature() {
    // TODO: Write actual test
    assert!(true); // ‚ùå Meaningless assertion
}

// ‚ùå NEVER COMMIT - Hardcoded placeholder values
let memory_mb = 0; // Placeholder - would get actual memory usage
let result = "placeholder_response"; // TODO: Get real response
```

### **Acceptable Temporary Patterns (With Strict Rules)**

```rust
// ‚úÖ ACCEPTABLE - Development-only features with clear annotations
#[cfg(feature = "development")]
fn development_mock() -> Data {
    // This is intentionally a mock for development/testing only
    Data::mock()
}

// ‚úÖ ACCEPTABLE - Explicit future work with GitHub issues
// NOTE: Feature XYZ not yet implemented - tracked in Issue #123
// This function returns default behavior until Issue #123 is completed

// ‚úÖ ACCEPTABLE - Dead code that will be removed
#[allow(dead_code)] // Will be used in Issue #456 implementation
struct FutureFeature { ... }

// ‚úÖ ACCEPTABLE - Intentional unimplemented with clear context
fn experimental_feature() -> Result<()> {
    // This feature is intentionally not implemented until design review
    // completes. See design doc: docs/experimental-feature.md
    Err("Feature not yet available".into())
}
```

## Pre-Commit Verification Checklist

**Rule: Complete this checklist before EVERY commit. No exceptions.**

### **Code Completeness Verification**
```bash
# 1. Search for prohibited patterns (MUST return zero results)
grep -r "TODO" src/ --include="*.rs"
grep -r "FIXME" src/ --include="*.rs" 
grep -r "placeholder" src/ --include="*.rs"
grep -r "stub" src/ --include="*.rs"
grep -r "unimplemented!" src/ --include="*.rs"
grep -r "todo!()" src/ --include="*.rs"

# 2. Search for placeholder test patterns
grep -r "assert!(true)" tests/ --include="*.rs"
grep -r "// TODO:" tests/ --include="*.rs"
```

### **Implementation Verification Checklist**
- [ ] **Zero TODO/FIXME comments** in committed code
- [ ] **Zero placeholder implementations** (functions that return mock/dummy data)
- [ ] **Zero stub functions** (functions with empty bodies or `unimplemented!()`)
- [ ] **All functions have real implementations** that perform their intended purpose
- [ ] **All tests actually test functionality** (no `assert!(true)` placeholders)
- [ ] **All error paths are implemented** (not just success paths)
- [ ] **All configuration options are functional** (not just parsed but ignored)
- [ ] **All performance requirements are met** (not estimated or placeholder metrics)

### **Quality Verification Checklist**
- [ ] **All public APIs have comprehensive rustdoc** with working examples
- [ ] **All functions handle errors appropriately** (not just `.unwrap()` or `.expect()`)
- [ ] **All performance-critical paths are optimized** (not just basic implementations)
- [ ] **All security requirements are implemented** (not just documented)
- [ ] **All integration points are functional** (not mocked in production code)

## Implementation Standards by Code Type

### **Function Implementation Standards**

```rust
// ‚ùå INCOMPLETE - Function exists but doesn't work
pub fn analyze_performance(code: &str) -> PerformanceMetrics {
    // TODO: Implement actual analysis
    PerformanceMetrics::default()
}

// ‚úÖ COMPLETE - Function fully implements its contract
pub fn analyze_performance(code: &str) -> Result<PerformanceMetrics> {
    let ast = parse_code(code)?;
    let complexity = calculate_complexity(&ast)?;
    let memory_usage = estimate_memory_usage(&ast)?;
    let execution_time = estimate_execution_time(&ast)?;
    
    Ok(PerformanceMetrics {
        complexity,
        memory_usage,
        execution_time,
        bottlenecks: identify_bottlenecks(&ast)?,
        optimizations: suggest_optimizations(&ast)?,
    })
}
```

### **Test Implementation Standards**

```rust
// ‚ùå INCOMPLETE - Test exists but doesn't verify functionality
#[test]
fn test_performance_analysis() {
    // TODO: Write actual test
    assert!(true);
}

// ‚úÖ COMPLETE - Test thoroughly verifies functionality
#[test]
fn test_performance_analysis_comprehensive() {
    let code = r#"
        def fibonacci(n):
            if n <= 1: return n
            return fibonacci(n-1) + fibonacci(n-2)
    "#;
    
    let metrics = analyze_performance(code).unwrap();
    
    // Verify all expected metrics are calculated
    assert!(metrics.complexity > 0);
    assert!(metrics.memory_usage.is_some());
    assert!(metrics.execution_time.is_some());
    assert!(!metrics.bottlenecks.is_empty());
    assert!(!metrics.optimizations.is_empty());
    
    // Verify specific algorithm detection
    assert!(metrics.optimizations.iter()
        .any(|opt| opt.contains("memoization")));
}
```

### **Configuration Implementation Standards**

```rust
// ‚ùå INCOMPLETE - Configuration parsed but ignored
#[derive(Deserialize)]
struct Config {
    performance_monitoring: bool, // TODO: Actually use this setting
    max_memory_mb: u64, // TODO: Implement memory limits
}

// ‚úÖ COMPLETE - Configuration is parsed and actively used
#[derive(Deserialize)]
struct Config {
    performance_monitoring: bool,
    max_memory_mb: u64,
}

impl Config {
    pub fn is_monitoring_enabled(&self) -> bool {
        self.performance_monitoring
    }
    
    pub fn enforce_memory_limit(&self, current_usage: u64) -> Result<()> {
        if current_usage > self.max_memory_mb {
            return Err(format!("Memory usage {}MB exceeds limit {}MB", 
                current_usage, self.max_memory_mb).into());
        }
        Ok(())
    }
}
```

## Git Workflow Integration

### **Pre-Commit Hook Implementation**

Create `.git/hooks/pre-commit`:
```bash
#!/bin/bash
set -e

echo "üîç Checking for incomplete implementations..."

# Check for prohibited patterns
if grep -r "TODO\|FIXME\|placeholder\|stub implementation" src/ --include="*.rs" --quiet; then
    echo "‚ùå COMMIT BLOCKED: Found TODO/FIXME/placeholder code"
    echo "Found prohibited patterns:"
    grep -r "TODO\|FIXME\|placeholder\|stub implementation" src/ --include="*.rs" -n
    echo ""
    echo "Complete all implementations before committing."
    exit 1
fi

# Check for unimplemented/todo macros
if grep -r "unimplemented!\|todo!()" src/ --include="*.rs" --quiet; then
    echo "‚ùå COMMIT BLOCKED: Found unimplemented!() or todo!() macros"
    grep -r "unimplemented!\|todo!()" src/ --include="*.rs" -n
    exit 1
fi

# Check for placeholder tests
if grep -r "assert!(true)" tests/ --include="*.rs" --quiet; then
    echo "‚ùå COMMIT BLOCKED: Found placeholder tests with assert!(true)"
    grep -r "assert!(true)" tests/ --include="*.rs" -n
    exit 1
fi

echo "‚úÖ No incomplete implementations found"

# Run tests to ensure functionality works
echo "üß™ Running tests to verify functionality..."
cargo test --quiet || {
    echo "‚ùå COMMIT BLOCKED: Tests failed"
    exit 1
}

echo "‚úÖ All checks passed - commit allowed"
```

### **Commit Message Requirements**

```bash
# ‚úÖ GOOD - Commit message indicates complete implementation
git commit -m "feat(auth): implement complete JWT authentication system

- Add JWT token generation and validation
- Implement token refresh mechanism  
- Add comprehensive error handling for all auth flows
- Include rate limiting and security headers
- Add integration tests for all authentication paths
- Performance: <100ms token validation, <50ms generation

All functionality fully implemented and tested."

# ‚ùå BAD - Commit message hints at incomplete work
git commit -m "feat(auth): add authentication framework

- Basic JWT structure in place
- TODO: Add validation logic
- TODO: Implement refresh tokens
- Basic tests added"
```

## Issue Completion Standards

### **Definition of Done Checklist**

Before marking any GitHub issue as complete:

```markdown
## Implementation Verification (Required)
- [ ] All code paths have real implementations (no TODOs/placeholders)
- [ ] All functions perform their documented purpose
- [ ] All error conditions are handled appropriately
- [ ] All performance requirements are met with real measurements
- [ ] All tests verify actual functionality (not placeholder assertions)

## Integration Verification (Required)  
- [ ] Feature works with existing codebase without mocking
- [ ] All dependencies are real (not stubbed for testing)
- [ ] All configuration options are functional
- [ ] All APIs return real data (not mock responses)
- [ ] All database/external integrations work with real services

## Quality Verification (Required)
- [ ] Code review completed with focus on implementation completeness
- [ ] All automated tests pass with real implementations
- [ ] Performance benchmarks meet requirements with actual measurements
- [ ] Security review completed for real implementation
- [ ] Documentation reflects actual functionality (not planned features)

## Demonstration Requirement
- [ ] **Live demo completed** showing all claimed functionality working
- [ ] Demo includes error cases and edge conditions
- [ ] Demo shows integration with real services/dependencies
- [ ] Performance characteristics demonstrated with real measurements
```

## Enforcement and Accountability

### **Code Review Standards**

**Reviewer Requirements:**
- Must verify zero placeholder/stub code in PR
- Must test actual functionality, not just code structure
- Must validate that all claims in PR description are demonstrable
- Must require fixes for any TODO/FIXME comments found

### **CI/CD Integration**

Add to GitHub Actions workflows:
```yaml
- name: Check for incomplete implementations
  run: |
    if grep -r "TODO\|FIXME\|placeholder\|stub" src/ --include="*.rs" --quiet; then
      echo "‚ùå CI FAILED: Found incomplete implementations"
      grep -r "TODO\|FIXME\|placeholder\|stub" src/ --include="*.rs" -n
      exit 1
    fi
    
    if grep -r "unimplemented!\|todo!()" src/ --include="*.rs" --quiet; then
      echo "‚ùå CI FAILED: Found unimplemented macros"
      exit 1
    fi
```

### **Project Status Verification**

**Monthly Audit Requirements:**
- Scan entire codebase for prohibited patterns
- Verify all "completed" features actually work end-to-end
- Test all claimed performance characteristics with real measurements
- Validate all documentation against actual implementation

## Examples from MCP Test Harness Audit

### **What Went Wrong**
Based on recent audit findings, these patterns led to 60%+ placeholder implementations being marked as "complete":

```rust
// Found in "complete" code:
// TODO: Replace with actual MCP client execution
// TODO: Implement actual transport communication  
// For now, provide stub implementation that validates data structures
// Placeholder implementation - returns mock response for security testing

vec![self.execute_test_case("find_references", "placeholder", ...
vec![self.execute_test_case("explain_symbol", "placeholder", ...
```

### **How to Fix**
Replace placeholder implementations with functional code:

```rust
// ‚ùå BEFORE - Placeholder implementation
async fn execute_test_case(tool: &str, input: Value) -> TestResult {
    // TODO: Replace with actual MCP client execution
    TestResult::placeholder_success()
}

// ‚úÖ AFTER - Complete implementation  
async fn execute_test_case(tool: &str, input: Value) -> TestResult {
    let client = McpClient::connect(&self.server_config).await?;
    let request = JsonRpcRequest::new(tool, input);
    let response = client.send_request(request).await?;
    let validation_result = self.validator.validate(&response)?;
    
    TestResult {
        success: validation_result.passed,
        duration: response.duration,
        output: response.data,
        errors: validation_result.errors,
    }
}
```

---

**Summary:** This rule prevents the systematic placeholder implementation problem discovered in our MCP Test Harness audit. Every commit must contain complete, functional implementations with zero placeholder code.

**Enforcement:** Pre-commit hooks, CI/CD checks, code review requirements, and regular audits ensure compliance.

**Goal:** 100% functional code in every commit, with no exceptions for placeholder implementations.
