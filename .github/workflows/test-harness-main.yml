name: MCP Test Harness - Main Branch

on:
  push:
    branches: [ main ]
    paths:
      - 'crates/**'
      - 'test-projects/**'
      - 'Cargo.toml'
      - 'Cargo.lock'
  workflow_dispatch:
    inputs:
      full_suite:
        description: 'Run full comprehensive test suite'
        required: false
        default: 'false'
        type: boolean

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  # Comprehensive test harness execution
  comprehensive-testing:
    name: Comprehensive Test Execution
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    strategy:
      matrix:
        test-category:
          - core-tools-comprehensive
          - search-analysis-comprehensive  
          - workflow-edge-cases-comprehensive
          - integration-performance
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Setup Rust cache
        uses: Swatinem/rust-cache@v2
        with:
          key: main-comprehensive-${{ matrix.test-category }}-${{ runner.os }}

      - name: Install comprehensive dependencies
        run: |
          # System dependencies
          sudo apt-get update
          sudo apt-get install -y nodejs npm python3 python3-pip jq time hyperfine
          
          # Node.js and MCP servers
          curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
          sudo apt-get install -y nodejs
          npm install -g @modelcontextprotocol/server-filesystem@latest
          npm install -g @modelcontextprotocol/server-memory@latest
          
          # Python dependencies for validation scripts
          pip3 install pyyaml jsonschema

      - name: Build all components
        run: |
          cargo build --release --all-features
          cargo build --release -p codeprism-test-harness

      - name: Execute comprehensive test category - ${{ matrix.test-category }}
        id: comprehensive-tests
        run: |
          cd crates/codeprism-test-harness
          
          case "${{ matrix.test-category }}" in
            "core-tools-comprehensive")
              echo "Running comprehensive core tools testing..."
              for config in config/core-tools/*/*.yaml; do
                echo "Testing: $config"
                cargo run --release -- --config "$config" --comprehensive --performance-tracking
              done
              ;;
            "search-analysis-comprehensive")
              echo "Running comprehensive search and analysis tools testing..."
              for config in config/search-tools/*/*.yaml config/analysis-tools/*/*.yaml; do
                echo "Testing: $config"
                cargo run --release -- --config "$config" --comprehensive --performance-tracking
              done
              ;;
            "workflow-edge-cases-comprehensive")
              echo "Running comprehensive workflow and edge case testing..."
              for config in config/workflow-tools/*/*.yaml config/edge-cases/*/*.yaml; do
                echo "Testing: $config"
                cargo run --release -- --config "$config" --comprehensive --performance-tracking
              done
              ;;
            "integration-performance")
              echo "Running integration and performance testing..."
              for config in config/integration/*.yaml; do
                echo "Testing: $config"
                cargo run --release -- --config "$config" --comprehensive --performance-tracking --concurrent-testing
              done
              ;;
          esac

      - name: Generate test report
        if: always()
        run: |
          cd crates/codeprism-test-harness
          
          echo "# Test Results - ${{ matrix.test-category }}" > test-report-${{ matrix.test-category }}.md
          echo "" >> test-report-${{ matrix.test-category }}.md
          echo "**Branch:** main | **Commit:** ${{ github.sha }}" >> test-report-${{ matrix.test-category }}.md
          echo "**Test Category:** ${{ matrix.test-category }}" >> test-report-${{ matrix.test-category }}.md
          echo "" >> test-report-${{ matrix.test-category }}.md
          
          # Aggregate test results
          if [ -d "test-results" ]; then
            echo "## Test Summary" >> test-report-${{ matrix.test-category }}.md
            echo "" >> test-report-${{ matrix.test-category }}.md
            
            total_tests=$(find test-results -name "*.json" | wc -l)
            passed_tests=$(find test-results -name "*.json" -exec grep -l '"status":"passed"' {} \; | wc -l)
            failed_tests=$(find test-results -name "*.json" -exec grep -l '"status":"failed"' {} \; | wc -l)
            
            echo "- **Total Tests:** $total_tests" >> test-report-${{ matrix.test-category }}.md
            echo "- **Passed:** $passed_tests" >> test-report-${{ matrix.test-category }}.md
            echo "- **Failed:** $failed_tests" >> test-report-${{ matrix.test-category }}.md
            echo "" >> test-report-${{ matrix.test-category }}.md
            
            if [ $failed_tests -gt 0 ]; then
              echo "## Failed Tests" >> test-report-${{ matrix.test-category }}.md
              find test-results -name "*.json" -exec grep -l '"status":"failed"' {} \; | head -10 | while read file; do
                test_name=$(basename "$file" .json)
                echo "- $test_name" >> test-report-${{ matrix.test-category }}.md
              done
            fi
          fi

      - name: Upload comprehensive test results
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-results-${{ matrix.test-category }}
          path: |
            crates/codeprism-test-harness/test-results/
            crates/codeprism-test-harness/reports/
            crates/codeprism-test-harness/performance-data/
            crates/codeprism-test-harness/test-report-${{ matrix.test-category }}.md
          retention-days: 30

  # Performance baseline update
  performance-baseline-update:
    name: Update Performance Baselines
    runs-on: ubuntu-latest
    needs: comprehensive-testing
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Setup Rust cache
        uses: Swatinem/rust-cache@v2
        with:
          key: performance-baseline-${{ runner.os }}

      - name: Download performance data
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: Install performance analysis tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq python3 python3-pip
          pip3 install numpy pandas

      - name: Run performance benchmarks
        run: |
          cargo build --release --benches
          cargo bench --bench comprehensive -- --output-format json > current-benchmarks.json

      - name: Analyze and update baselines
        id: baseline-update
        run: |
          python3 - << 'PYTHON'
          import json
          import os
          import statistics
          from pathlib import Path
          
          # Load current benchmark results
          with open('current-benchmarks.json', 'r') as f:
              current_results = json.load(f)
          
          # Download existing baselines if available
          baseline_path = Path('performance-baselines/baseline.json')
          if baseline_path.exists():
              with open(baseline_path, 'r') as f:
                  existing_baselines = json.load(f)
          else:
              existing_baselines = {"results": []}
          
          # Performance improvement detection and baseline updates
          updated_baselines = {"results": []}
          improvements = []
          
          for result in current_results.get('results', []):
              test_id = result.get('id', '')
              current_time = result.get('typical', {}).get('estimate', 0)
              
              # Find existing baseline
              existing_baseline = None
              for baseline in existing_baselines.get('results', []):
                  if baseline.get('id') == test_id:
                      existing_baseline = baseline
                      break
              
              if existing_baseline:
                  baseline_time = existing_baseline.get('typical', {}).get('estimate', 0)
                  # Update baseline if current is significantly better (>10% improvement)
                  if current_time < baseline_time * 0.9:
                      improvements.append({
                          'test': test_id,
                          'old_time': baseline_time,
                          'new_time': current_time,
                          'improvement': (1 - current_time / baseline_time) * 100
                      })
                      updated_baselines['results'].append(result)
                  else:
                      updated_baselines['results'].append(existing_baseline)
              else:
                  # New test, add as baseline
                  updated_baselines['results'].append(result)
          
          # Save updated baselines
          os.makedirs('performance-baselines', exist_ok=True)
          with open('performance-baselines/baseline.json', 'w') as f:
              json.dump(updated_baselines, f, indent=2)
          
          # Generate improvement report
          if improvements:
              with open('performance-improvements.md', 'w') as f:
                  f.write("# Performance Improvements Detected\n\n")
                  f.write(f"**Commit:** {os.environ.get('GITHUB_SHA', 'unknown')}\n\n")
                  for imp in improvements:
                      f.write(f"- **{imp['test']}**: {imp['improvement']:.1f}% faster\n")
                  f.write(f"\n**Total improvements:** {len(improvements)}\n")
              
              print(f"PERFORMANCE_IMPROVEMENTS={len(improvements)}")
          else:
              print("PERFORMANCE_IMPROVEMENTS=0")
          PYTHON

      - name: Upload updated baselines
        uses: actions/upload-artifact@v4
        with:
          name: performance-baselines
          path: |
            performance-baselines/
            performance-improvements.md
          retention-days: 90

      - name: Commit baseline updates
        if: steps.baseline-update.outputs.PERFORMANCE_IMPROVEMENTS > 0
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add performance-baselines/
          git commit -m "chore: update performance baselines after improvements

          - Detected ${{ steps.baseline-update.outputs.PERFORMANCE_IMPROVEMENTS }} performance improvements
          - Baselines updated for main branch commit ${{ github.sha }}
          - See performance-improvements.md for details"
          git push

  # Generate comprehensive report
  comprehensive-report:
    name: Generate Comprehensive Report
    runs-on: ubuntu-latest
    needs: [comprehensive-testing, performance-baseline-update]
    if: always()
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: Generate comprehensive report
        run: |
          echo "# 📊 MCP Test Harness - Main Branch Report" > comprehensive-report.md
          echo "" >> comprehensive-report.md
          echo "**Branch:** main | **Commit:** ${{ github.sha }}" >> comprehensive-report.md
          echo "**Timestamp:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> comprehensive-report.md
          echo "" >> comprehensive-report.md
          
          # Test execution summary
          echo "## �� Test Execution Summary" >> comprehensive-report.md
          echo "" >> comprehensive-report.md
          
          if [ "${{ needs.comprehensive-testing.result }}" = "success" ]; then
            echo "✅ **Comprehensive Testing**: All test categories passed" >> comprehensive-report.md
          else
            echo "❌ **Comprehensive Testing**: Some test categories failed" >> comprehensive-report.md
          fi
          
          if [ "${{ needs.performance-baseline-update.result }}" = "success" ]; then
            echo "✅ **Performance Baselines**: Updated successfully" >> comprehensive-report.md
          else
            echo "⚠️ **Performance Baselines**: Update had issues" >> comprehensive-report.md
          fi
          
          echo "" >> comprehensive-report.md
          
          # Aggregate test statistics
          echo "## 📈 Test Statistics" >> comprehensive-report.md
          echo "" >> comprehensive-report.md
          
          total_configs=0
          total_tests=0
          total_passed=0
          total_failed=0
          
          for report in artifacts/comprehensive-results-*/test-report-*.md; do
            if [ -f "$report" ]; then
              cat "$report" >> comprehensive-report.md
              echo "" >> comprehensive-report.md
              echo "---" >> comprehensive-report.md
              echo "" >> comprehensive-report.md
            fi
          done
          
          # Performance improvements
          if [ -f artifacts/performance-baselines/performance-improvements.md ]; then
            echo "" >> comprehensive-report.md
            cat artifacts/performance-baselines/performance-improvements.md >> comprehensive-report.md
          fi
          
          echo "" >> comprehensive-report.md
          echo "*Report generated by MCP Test Harness CI/CD Pipeline*" >> comprehensive-report.md

      - name: Upload comprehensive report
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-report
          path: comprehensive-report.md
          retention-days: 90

      - name: Create GitHub release on major improvements
        if: needs.performance-baseline-update.outputs.PERFORMANCE_IMPROVEMENTS > 5
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Check if we should create a release for significant improvements
            const improvements = parseInt('${{ needs.performance-baseline-update.outputs.PERFORMANCE_IMPROVEMENTS }}') || 0;
            
            if (improvements > 5) {
              const reportContent = fs.readFileSync('comprehensive-report.md', 'utf8');
              
              await github.rest.repos.createRelease({
                owner: context.repo.owner,
                repo: context.repo.repo,
                tag_name: `performance-improvement-${Date.now()}`,
                name: `Performance Improvements - ${improvements} optimizations`,
                body: reportContent,
                draft: true,
                prerelease: false
              });
            }
