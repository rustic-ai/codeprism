# Resource Limits Edge Case Testing
# Tests handling of memory constraints, timeouts, and resource exhaustion

global:
  max_global_concurrency: 2  # Lower concurrency for resource testing
  timeout_seconds: 60
  fail_fast: false
  default_project_path: "test-projects/dependency-test-project"

# Performance monitoring for resource limit testing
performance:
  enable_monitoring: true
  baseline_storage_path: "baselines/edge-cases/"
  regression_detection:
    warning_threshold_percent: 60.0
    error_threshold_percent: 120.0

test_suites:
  - name: "Resource Limits - Memory Constraints"
    description: "Test tools under memory pressure and constraints"
    test_cases:
      # Memory-intensive repository analysis
      - id: "resource_limits_repository_stats_memory"
        tool_name: "repository_stats"
        description: "Repository stats with memory constraints"
        enabled: true
        project_path: "test-projects/dependency-test-project"
        input_params:
          include_complexity: true
          include_file_types: true
          include_line_count: true
          deep_analysis: true
          max_file_size: 1048576  # 1MB files
        expected:
          patterns:
            - key: "result"
              validation:
                type: "exists"
              required: true
          performance_requirements:
            max_execution_time_ms: 10000
            max_memory_usage_mb: 64  # Constrained memory
          custom_scripts:
            - name: "validate_memory_efficiency"
              language: "python"
              script: |
                def validate(response):
                    if 'error' in response:
                        error_msg = response.get('error', {}).get('message', '').lower()
                        if 'memory' in error_msg or 'timeout' in error_msg:
                            return True, 0.8, "Handled memory constraint gracefully"
                        else:
                            return True, 0.6, f"Error under memory pressure: {error_msg}"
                    
                    result = response.get('result', {})
                    if result:
                        return True, 1.0, "Successfully completed under memory constraints"
                    
                    return False, 0.0, "Unexpected response under memory pressure"

      # Large-scale security analysis
      - id: "resource_limits_analyze_security_large"
        tool_name: "analyze_security"
        description: "Security analysis of large project"
        enabled: true
        project_path: "test-projects/dependency-test-project"
        input_params:
          scan_type: "comprehensive"
          include_dependencies: true
          deep_scan: true
          max_scan_depth: 10
        expected:
          patterns:
            - key: "result"
              validation:
                type: "exists"
              required: true
          performance_requirements:
            max_execution_time_ms: 30000
            max_memory_usage_mb: 96
          custom_scripts:
            - name: "validate_large_scan_handling"
              language: "python"
              script: |
                def validate(response):
                    if 'error' in response:
                        return True, 0.7, "Handled large scan with error (acceptable)"
                    
                    result = response.get('result', {})
                    vulnerabilities = result.get('vulnerabilities', [])
                    
                    # Large scan should find some results or report completion
                    if len(vulnerabilities) >= 0:  # Accept any result including 0
                        return True, 1.0, f"Completed large security scan: {len(vulnerabilities)} findings"
                    
                    return False, 0.0, "Unexpected result from large security scan"

      # Memory-intensive duplicate detection
      - id: "resource_limits_find_duplicates_memory"
        tool_name: "find_duplicates"
        description: "Duplicate detection with memory constraints"
        enabled: true
        project_path: "test-projects/dependency-test-project"
        input_params:
          similarity_threshold: 0.6  # Lower threshold = more comparisons
          analysis_scope: "cross-file"
          include_similar_functions: true
          max_file_size: 102400  # 100KB files
        expected:
          patterns:
            - key: "result"
              validation:
                type: "exists"
              required: true
          performance_requirements:
            max_execution_time_ms: 20000
            max_memory_usage_mb: 80

  - name: "Resource Limits - Timeout Handling"
    description: "Test timeout handling and graceful degradation"
    test_cases:
      # Quick timeout test
      - id: "resource_limits_analyze_performance_timeout"
        tool_name: "analyze_performance"
        description: "Performance analysis with tight timeout"
        enabled: true
        project_path: "test-projects/dependency-test-project"
        input_params:
          analysis_type: "comprehensive"
          include_profiling: true
          timeout_ms: 5000  # Tight timeout
        expected:
          patterns:
            - key: "result"
              validation:
                type: "exists"
              required: false
          allow_failure: true
          performance_requirements:
            max_execution_time_ms: 6000  # Allow slight overage
          custom_scripts:
            - name: "validate_timeout_handling"
              language: "python"
              script: |
                def validate(response):
                    if 'error' in response:
                        error_msg = response.get('error', {}).get('message', '').lower()
                        if 'timeout' in error_msg or 'time' in error_msg:
                            return True, 1.0, "Properly handled timeout"
                        else:
                            return True, 0.7, f"Error on timeout: {error_msg}"
                    
                    result = response.get('result', {})
                    if result:
                        partial = result.get('partial_results', False)
                        if partial:
                            return True, 0.9, "Returned partial results before timeout"
                        else:
                            return True, 1.0, "Completed within timeout"
                    
                    return False, 0.0, "Unexpected timeout response"

      # Batch analysis timeout
      - id: "resource_limits_batch_analysis_timeout"
        tool_name: "batch_analysis"
        description: "Batch analysis with timeout handling"
        enabled: true
        project_path: "test-projects/python-sample"
        input_params:
          analysis_sequence:
            - tool: "analyze_security"
              params:
                scan_type: "comprehensive"
                timeout_ms: 3000
            - tool: "analyze_performance"
              params:
                analysis_type: "comprehensive"
                timeout_ms: 3000
            - tool: "find_duplicates"
              params:
                similarity_threshold: 0.7
                timeout_ms: 3000
          execution_mode: "sequential"
          continue_on_timeout: true
          global_timeout_ms: 10000
        expected:
          patterns:
            - key: "result"
              validation:
                type: "exists"
              required: true
          allow_failure: true

  - name: "Resource Limits - Large Data Handling"
    description: "Test handling of large datasets and files"
    test_cases:
      # Large file search
      - id: "resource_limits_search_content_large_files"
        tool_name: "search_content"
        description: "Content search in large files"
        enabled: true
        project_path: "test-projects/dependency-test-project"
        input_params:
          query: "import|require|include"
          regex_mode: true
          include_code: true
          max_file_size: 1048576  # 1MB max file size
          max_results: 1000
        expected:
          patterns:
            - key: "result"
              validation:
                type: "exists"
              required: true
          performance_requirements:
            max_execution_time_ms: 15000
            max_memory_usage_mb: 72
          custom_scripts:
            - name: "validate_large_file_search"
              language: "python"
              script: |
                def validate(response):
                    if 'error' in response:
                        return True, 0.8, "Handled large file search with error"
                    
                    result = response.get('result', {})
                    matches = result.get('matches', [])
                    truncated = result.get('results_truncated', False)
                    
                    if truncated:
                        return True, 1.0, f"Properly truncated large results: {len(matches)} matches"
                    else:
                        return True, 0.9, f"Completed large file search: {len(matches)} matches"

      # Large symbol search
      - id: "resource_limits_search_symbols_large"
        tool_name: "search_symbols"
        description: "Symbol search with large result sets"
        enabled: true
        project_path: "test-projects/dependency-test-project"
        input_params:
          query: "*"  # Match all symbols
          language: "python"
          max_results: 500
          include_private: true
          include_builtin: true
        expected:
          patterns:
            - key: "result"
              validation:
                type: "exists"
              required: true
          performance_requirements:
            max_execution_time_ms: 12000
            max_memory_usage_mb: 64

  - name: "Resource Limits - Concurrent Stress"
    description: "Test resource handling under concurrent load"
    test_cases:
      # Concurrent repository analysis
      - id: "resource_limits_concurrent_repository_stats"
        tool_name: "repository_stats"
        description: "Concurrent repository stats analysis"
        enabled: true
        project_path: "test-projects/python-sample"
        input_params:
          include_complexity: true
          concurrent_analysis: true
        expected:
          patterns:
            - key: "result"
              validation:
                type: "exists"
              required: true
          performance_requirements:
            max_execution_time_ms: 8000
            max_memory_usage_mb: 48
        # This test will be run multiple times concurrently
        concurrency_test:
          concurrent_requests: 3
          validate_isolation: true

      # Concurrent security analysis
      - id: "resource_limits_concurrent_security"
        tool_name: "analyze_security"
        description: "Concurrent security analysis"
        enabled: true
        project_path: "test-projects/python-sample"
        input_params:
          scan_type: "basic"
          concurrent_safe: true
        expected:
          patterns:
            - key: "result"
              validation:
                type: "exists"
              required: true
        concurrency_test:
          concurrent_requests: 2
          validate_isolation: true

# Performance baselines for resource limit testing
baselines:
  resource_limits_repository_stats_memory:
    average_execution_time_ms: 5000.0
    peak_memory_mb: 56.0
    throughput_ops_per_sec: 0.2
  resource_limits_analyze_security_large:
    average_execution_time_ms: 15000.0
    peak_memory_mb: 80.0
    throughput_ops_per_sec: 0.067
  resource_limits_find_duplicates_memory:
    average_execution_time_ms: 12000.0
    peak_memory_mb: 72.0
    throughput_ops_per_sec: 0.083
  resource_limits_analyze_performance_timeout:
    average_execution_time_ms: 4500.0
    peak_memory_mb: 32.0
    throughput_ops_per_sec: 0.22
