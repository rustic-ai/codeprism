# Core Tools Integration Workflow Test Configuration
# Tests realistic workflows that combine multiple MCP tools

global:
  max_global_concurrency: 1  # Sequential execution for workflow testing
  timeout_seconds: 60
  fail_fast: false
  default_project_path: "test-projects/python-sample"

# Performance monitoring for integration workflows
performance:
  enable_monitoring: true
  baseline_storage_path: "baselines/integration/"
  regression_detection:
    warning_threshold_percent: 30.0
    error_threshold_percent: 75.0

test_suites:
  - name: "Core Tools Integration - Analysis Workflow"
    description: "Test integrated workflows combining repository analysis, symbol search, and dependency tracking"
    test_cases:
      # Workflow 1: Repository Discovery → Symbol Analysis → Dependency Mapping
      - id: "workflow_repo_to_dependencies"
        tool_name: "repository_stats"
        description: "Step 1: Analyze repository to understand structure"
        enabled: true
        project_path: "test-projects/python-sample"
        input_params:
          include_hidden: false
          include_complexity: true
          include_dependencies: true
          file_patterns: ["*.py"]
        expected:
          patterns:
            - key: "result.total_files"
              validation:
                type: "range"
                min: 5
                max: 50
              required: true
            - key: "result.languages_detected"
              validation:
                type: "contains"
                values: ["Python"]
              required: true
          performance_requirements:
            max_execution_time_ms: 3000
            max_memory_usage_mb: 64
          custom_scripts:
            - name: "extract_analysis_data"
              language: "python"
              script: |
                def validate(response):
                    """Extract data for subsequent workflow steps"""
                    result = response.get('result', {})
                    
                    # Store key metrics for next steps
                    global workflow_data
                    workflow_data = {
                        'total_files': result.get('total_files', 0),
                        'languages': result.get('languages_detected', []),
                        'file_types': result.get('file_types', {}),
                        'complexity': result.get('complexity_metrics', {})
                    }
                    
                    if workflow_data['total_files'] > 0:
                        return True, 1.0, f"Repository analysis complete: {workflow_data['total_files']} files"
                    else:
                        return False, 0.0, "No files found in repository analysis"

      # Step 2: Search for key symbols based on repository analysis
      - id: "workflow_search_key_symbols"
        tool_name: "search_symbols"
        description: "Step 2: Search for key symbols found in repository"
        enabled: true
        project_path: "test-projects/python-sample"
        input_params:
          query: "class:*"  # Search for all classes
          language: "python"
          include_private: false
          max_results: 20
        expected:
          patterns:
            - key: "result.symbols"
              validation:
                type: "array_min_length"
                min_length: 1
              required: true
          custom_scripts:
            - name: "prepare_dependency_analysis"
              language: "python"
              script: |
                def validate(response):
                    """Prepare symbols for dependency analysis"""
                    result = response.get('result', {})
                    symbols = result.get('symbols', [])
                    
                    if not symbols:
                        return False, 0.0, "No symbols found for dependency analysis"
                    
                    # Extract class names for dependency analysis
                    global workflow_symbols
                    workflow_symbols = [
                        {
                            'name': symbol.get('name'),
                            'type': symbol.get('type'),
                            'file': symbol.get('file')
                        }
                        for symbol in symbols
                        if symbol.get('type') == 'class'
                    ]
                    
                    class_count = len(workflow_symbols)
                    return True, 1.0, f"Found {class_count} classes for dependency analysis"

      # Step 3: Analyze dependencies for discovered symbols
      - id: "workflow_analyze_dependencies"
        tool_name: "find_dependencies"
        description: "Step 3: Analyze dependencies for key symbols"
        enabled: true
        project_path: "test-projects/python-sample"
        input_params:
          target_symbol: "User"  # Analyze a common class name
          symbol_type: "class"
          language: "python"
          include_imports: true
          include_inheritance: true
          max_depth: 3
        expected:
          patterns:
            - key: "result.dependencies"
              validation:
                type: "array"
              required: true
          performance_requirements:
            max_execution_time_ms: 4000
            max_memory_usage_mb: 80
          custom_scripts:
            - name: "validate_workflow_integration"
              language: "python"
              script: |
                def validate(response):
                    """Validate the complete workflow integration"""
                    result = response.get('result', {})
                    dependencies = result.get('dependencies', [])
                    
                    # Access data from previous workflow steps
                    global workflow_data, workflow_symbols
                    
                    # Validate workflow consistency
                    repo_files = getattr(validate, 'workflow_data', {}).get('total_files', 0)
                    found_symbols = len(getattr(validate, 'workflow_symbols', []))
                    dep_count = len(dependencies)
                    
                    # Calculate workflow completeness score
                    score = 0.0
                    feedback = []
                    
                    if repo_files > 0:
                        score += 0.4
                        feedback.append(f"repo analysis: {repo_files} files")
                    
                    if found_symbols > 0:
                        score += 0.3
                        feedback.append(f"symbol search: {found_symbols} classes")
                    
                    if dep_count >= 0:  # Dependencies might be empty for simple classes
                        score += 0.3
                        feedback.append(f"dependency analysis: {dep_count} dependencies")
                    
                    return True, score, f"Workflow integration: {'; '.join(feedback)}"

  - name: "Core Tools Integration - Cross-Language Analysis"
    description: "Test tools working across different programming languages"
    test_cases:
      # Multi-language repository analysis
      - id: "workflow_multi_language_analysis"
        tool_name: "repository_stats"
        description: "Analyze multi-language repository structure"
        enabled: true
        project_path: "test-projects/js-dependency-test-project"
        input_params:
          include_hidden: false
          detect_all_languages: true
          file_patterns: ["*.js", "*.jsx", "*.ts", "*.json"]
        expected:
          patterns:
            - key: "result.languages_detected"
              validation:
                type: "array_min_length"
                min_length: 1
              required: true
          custom_scripts:
            - name: "validate_multi_language"
              language: "python"
              script: |
                def validate(response):
                    result = response.get('result', {})
                    languages = result.get('languages_detected', [])
                    file_types = result.get('file_types', {})
                    
                    # Expect JavaScript/TypeScript detection
                    js_related = any(lang in ['JavaScript', 'TypeScript'] for lang in languages)
                    js_files = file_types.get('js', 0) + file_types.get('jsx', 0) + file_types.get('ts', 0)
                    
                    if js_related and js_files > 0:
                        return True, 1.0, f"Multi-language analysis: {len(languages)} languages, {js_files} JS/TS files"
                    elif js_files > 0:
                        return True, 0.7, f"Found {js_files} JS/TS files but language detection incomplete"
                    else:
                        return True, 0.3, f"Repository analyzed but no JS/TS files found"

      # Cross-language symbol search
      - id: "workflow_cross_language_symbols"
        tool_name: "search_symbols"
        description: "Search symbols across multiple languages"
        enabled: true
        project_path: "test-projects/js-dependency-test-project"
        input_params:
          query: "function:*"
          language: "javascript"
          include_private: false
          max_results: 30
        expected:
          patterns:
            - key: "result.symbols"
              validation:
                type: "array"
              required: true
          custom_scripts:
            - name: "validate_js_symbols"
              language: "python"
              script: |
                def validate(response):
                    result = response.get('result', {})
                    symbols = result.get('symbols', [])
                    
                    # Validate JavaScript-specific symbol properties
                    js_functions = sum(1 for s in symbols if s.get('type') == 'function')
                    
                    if js_functions > 0:
                        return True, 1.0, f"Found {js_functions} JavaScript functions"
                    elif symbols:
                        return True, 0.5, f"Found {len(symbols)} symbols (not all functions)"
                    else:
                        return True, 0.2, "No symbols found (may be valid for some projects)"

  - name: "Core Tools Integration - Performance Workflows"
    description: "Test performance characteristics of integrated tool workflows"
    test_cases:
      # Large project comprehensive analysis
      - id: "workflow_large_project_analysis"
        tool_name: "repository_stats"
        description: "Performance test on larger project with full analysis"
        enabled: true
        project_path: "test-projects/dependency-test-project"
        input_params:
          include_hidden: false
          include_complexity: true
          include_dependencies: true
          include_tests: true
          file_patterns: ["*.py", "*.js", "*.java"]
        expected:
          patterns:
            - key: "result.total_files"
              validation:
                type: "range"
                min: 1
                max: 200
              required: true
          performance_requirements:
            max_execution_time_ms: 8000
            max_memory_usage_mb: 128
          custom_scripts:
            - name: "validate_comprehensive_analysis"
              language: "python"
              script: |
                def validate(response):
                    result = response.get('result', {})
                    
                    # Check comprehensiveness of analysis
                    features = []
                    if result.get('total_files', 0) > 0:
                        features.append("file analysis")
                    if result.get('complexity_metrics'):
                        features.append("complexity analysis")
                    if result.get('dependency_analysis'):
                        features.append("dependency analysis")
                    if result.get('test_files_count') is not None:
                        features.append("test analysis")
                    
                    feature_count = len(features)
                    score = feature_count / 4.0  # 4 possible features
                    
                    return True, score, f"Comprehensive analysis: {', '.join(features)}"

  - name: "Core Tools Integration - Error Handling Workflows"
    description: "Test error handling and recovery in integrated workflows"
    test_cases:
      # Workflow with partial failures
      - id: "workflow_partial_failure_recovery"
        tool_name: "search_symbols"
        description: "Test workflow recovery from partial tool failures"
        enabled: true
        project_path: "test-projects/nonexistent"  # Non-existent project
        input_params:
          query: "class:*"
          language: "python"
        expected:
          patterns:
            - key: "error"
              validation:
                type: "exists"
              required: false
          allow_failure: true
          custom_scripts:
            - name: "validate_error_recovery"
              language: "python"
              script: |
                def validate(response):
                    # Test that errors are handled gracefully in workflows
                    if 'error' in response:
                        error_msg = response.get('error', '')
                        if 'not found' in error_msg.lower() or 'nonexistent' in error_msg.lower():
                            return True, 1.0, "Properly handled non-existent project error"
                        else:
                            return True, 0.7, f"Error handled: {error_msg}"
                    
                    # If no error, check for empty results
                    result = response.get('result', {})
                    if result.get('total_matches', -1) == 0:
                        return True, 0.8, "Gracefully handled with empty results"
                    
                    return False, 0.0, "Did not properly handle non-existent project"

# Performance baselines for integration workflows
baselines:
  workflow_repo_to_dependencies:
    average_execution_time_ms: 2000.0
    peak_memory_mb: 48.0
    throughput_ops_per_sec: 0.5
  workflow_search_key_symbols:
    average_execution_time_ms: 800.0
    peak_memory_mb: 32.0
    throughput_ops_per_sec: 1.25
  workflow_analyze_dependencies:
    average_execution_time_ms: 2500.0
    peak_memory_mb: 64.0
    throughput_ops_per_sec: 0.4
  workflow_large_project_analysis:
    average_execution_time_ms: 6000.0
    peak_memory_mb: 96.0
    throughput_ops_per_sec: 0.17 