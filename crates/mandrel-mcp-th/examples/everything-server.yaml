# Everything MCP Server Test Specification
# Comprehensive testing for MCP "everything" server covering all protocol capabilities
# following the MCP 2025-06-18 specification with sampling, logging, and experimental features

name: "Everything MCP Server"
version: "2025.7.1"
description: "Reference implementation MCP server exercising all protocol features"

# Complete MCP capabilities supported by everything server
capabilities:
  tools: true           # All 8 server tools  
  resources: true       # 100 test resources with pagination
  prompts: false        # Prompt templates not fully supported  
  sampling: false       # LLM sampling not supported (returns -32601)
  logging: true         # Random log messages every 15 seconds
  experimental:         # Extended experimental features
    progress_notifications: true
    resource_subscriptions: true
    annotation_system: true
    multi_transport: true

# Server startup configuration supporting multiple transports
server:
  command: "npx" 
  args: ["-y", "@modelcontextprotocol/server-everything"]
  env:
    NODE_ENV: "test"
    LOG_LEVEL: "info"
    ENABLE_PROGRESS: "true"
    SAMPLE_INTERVAL: "15000"    # Log message interval
    RESOURCE_UPDATE_INTERVAL: "5000"  # Resource subscription updates
  transport: "stdio"              # Primary transport, also supports SSE and HTTP
  startup_timeout_seconds: 30
  shutdown_timeout_seconds: 15

# ==========================================
# CUSTOM LUA VALIDATION SCRIPTS
# ==========================================

validation_scripts:
  # Mathematical validation with precision checking
  - name: "math_precision_validator"
    language: "lua"
    execution_phase: "after"
    description: "Validates mathematical operations with floating-point precision"
    required: true
    source: |
      -- Access to rich context: context.request, context.response, context.metadata
      local request = context.request
      local response = context.response
      
      -- Extract input parameters
      local a = request.params.a
      local b = request.params.b
      
      if a and b then
          -- Calculate expected result with Lua precision
          local expected = a + b
          
          -- Extract actual result from response text
          local result_text = response[1].text
          local actual = tonumber(result_text:match("[-+]?[%d]*%.?[%d]+"))
          
          -- Validate with tolerance for floating-point arithmetic
          local tolerance = 0.0001
          local difference = math.abs(expected - actual)
          
          result = {
              success = difference <= tolerance,
              message = string.format("Expected: %.6f, Actual: %.6f, Diff: %.6f", 
                                    expected, actual, difference),
              expected_value = expected,
              actual_value = actual,
              precision_check = difference <= tolerance
          }
      else
          result = {
              success = false,
              message = "Missing required parameters a or b"
          }
      end

  # Large text analysis and performance validation
  - name: "large_text_analyzer"
    language: "lua"
    execution_phase: "after"
    description: "Analyzes large text responses for completeness and performance"
    required: true
    source: |
      local response = context.response
      local metadata = context.metadata
      
      if response and response[1] and response[1].text then
          local text = response[1].text
          local text_length = string.len(text)
          local duration_ms = metadata.duration_ms
          
          -- Performance analysis
          local chars_per_ms = text_length / duration_ms
          local performance_grade = "A"
          
          if chars_per_ms < 1 then
              performance_grade = "C"
          elseif chars_per_ms < 10 then
              performance_grade = "B"
          end
          
          -- Content validation
          local has_expected_content = string.find(text, "Large text payload") ~= nil
          local has_performance_text = string.find(text, "performance") ~= nil
          
          result = {
              success = text_length >= 100 and has_expected_content,
              message = string.format("Text length: %d chars, Speed: %.2f chars/ms, Grade: %s", 
                                    text_length, chars_per_ms, performance_grade),
              metrics = {
                  text_length = text_length,
                  processing_speed_chars_per_ms = chars_per_ms,
                  performance_grade = performance_grade,
                  content_validation = {
                      has_expected_content = has_expected_content,
                      has_performance_text = has_performance_text
                  }
              }
          }
      else
          result = {
              success = false,
              message = "No text content found in response"
          }
      end

  # Unicode and internationalization validation
  - name: "unicode_validator"
    language: "lua"
    execution_phase: "after"
    description: "Validates Unicode character handling and encoding"
    required: true
    source: |
      local response = context.response
      
      if response and response[1] and response[1].text then
          local text = response[1].text
          
          -- Check for specific Unicode characters
          local has_rocket = string.find(text, "🚀") ~= nil
          local has_chinese = string.find(text, "你好世界") ~= nil
          local has_earth = string.find(text, "🌍") ~= nil
          local has_party = string.find(text, "🎉") ~= nil
          
          -- Count emoji characters (simplified detection)
          local emoji_count = 0
          for emoji in string.gmatch(text, "[🚀🌍🎉]") do
              emoji_count = emoji_count + 1
          end
          
          -- UTF-8 length validation (Lua 5.3+ supports utf8)
          local byte_length = string.len(text)
          
          result = {
              success = has_rocket and has_chinese and emoji_count >= 3,
              message = string.format("Unicode validation: %d emojis, %d bytes", 
                                    emoji_count, byte_length),
              unicode_features = {
                  rocket_emoji = has_rocket,
                  chinese_text = has_chinese,
                  earth_emoji = has_earth,
                  party_emoji = has_party,
                  emoji_count = emoji_count,
                  byte_length = byte_length
              }
          }
      else
          result = {
              success = false,
              message = "No text content found for Unicode validation"
          }
      end

  # Base64 image validation with format checking
  - name: "base64_image_validator"
    language: "lua"
    execution_phase: "after"
    description: "Validates Base64 encoded images with format verification"
    required: true
    source: |
      local response = context.response
      
      if response and response[1] and response[1].data then
          local data = response[1].data
          local response_type = response[1].type
          
          -- Validate response type
          local correct_type = response_type == "image"
          
          -- Validate Base64 PNG header
          local has_png_header = string.find(data, "data:image/png;base64,") == 1
          local has_base64_png_sig = string.find(data, "iVBORw0KGgo") ~= nil
          
          -- Calculate data size (Base64 encoded)
          local base64_data = data:match("data:image/png;base64,(.+)")
          local base64_length = base64_data and string.len(base64_data) or 0
          
          -- Estimate original size (Base64 is ~4/3 of original)
          local estimated_bytes = math.floor(base64_length * 3 / 4)
          
          -- PNG validation (simplified)
          local has_png_end = base64_data and string.find(base64_data, "AAAAASUVORK5CYII=") ~= nil
          
          result = {
              success = correct_type and has_png_header and has_base64_png_sig and base64_length > 100,
              message = string.format("Image validation: %s type, %d Base64 chars, ~%d bytes", 
                                    response_type, base64_length, estimated_bytes),
              image_analysis = {
                  correct_type = correct_type,
                  has_png_header = has_png_header,
                  has_png_signature = has_base64_png_sig,
                  has_png_end_marker = has_png_end,
                  base64_length = base64_length,
                  estimated_size_bytes = estimated_bytes
              }
          }
      else
          result = {
              success = false,
              message = "No image data found in response"
          }
      end

  # LLM response quality analysis
  - name: "llm_response_analyzer"
    language: "lua"
    execution_phase: "after"
    description: "Analyzes LLM-generated content for quality and appropriateness"
    required: false  # Non-critical since LLM responses can vary
    source: |
      local response = context.response
      local request = context.request
      local metadata = context.metadata
      
      if response and response[1] and response[1].text then
          local text = response[1].text
          local prompt = request.params.prompt or ""
          local max_tokens = request.params.maxTokens or 100
          
          -- Basic quality metrics
          local word_count = 0
          for word in string.gmatch(text, "%S+") do
              word_count = word_count + 1
          end
          
          local char_count = string.len(text)
          local sentence_count = 0
          for sentence in string.gmatch(text, "[.!?]+") do
              sentence_count = sentence_count + 1
          end
          
          -- Responsiveness to prompt
          local prompt_keywords = {}
          for word in string.gmatch(prompt:lower(), "%w+") do
              if string.len(word) > 3 then  -- Skip short words
                  table.insert(prompt_keywords, word)
              end
          end
          
          local keyword_matches = 0
          for _, keyword in ipairs(prompt_keywords) do
              if string.find(text:lower(), keyword) then
                  keyword_matches = keyword_matches + 1
              end
          end
          
          local responsiveness = #prompt_keywords > 0 and (keyword_matches / #prompt_keywords) or 0
          
          -- Token efficiency (rough estimate)
          local estimated_tokens = word_count * 1.3  -- Rough tokens-to-words ratio
          local token_efficiency = max_tokens > 0 and (estimated_tokens / max_tokens) or 0
          
          result = {
              success = word_count > 0 and char_count >= 5,  -- Basic sanity check
              message = string.format("LLM Analysis: %d words, %d chars, %.1f%% prompt responsiveness", 
                                    word_count, char_count, responsiveness * 100),
              quality_metrics = {
                  word_count = word_count,
                  character_count = char_count,
                  sentence_count = sentence_count,
                  estimated_tokens = estimated_tokens,
                  token_efficiency = token_efficiency,
                  prompt_responsiveness = responsiveness,
                  duration_ms = metadata.duration_ms,
                  words_per_second = metadata.duration_ms > 0 and (word_count / (metadata.duration_ms / 1000)) or 0
              }
          }
      else
          result = {
              success = false,
              message = "No LLM response text found"
          }
      end

  # Progress tracking and performance validation
  - name: "progress_performance_validator"
    language: "lua"
    execution_phase: "after"
    description: "Validates long-running operations with progress tracking"
    required: true
    source: |
      local response = context.response
      local request = context.request
      local metadata = context.metadata
      
      local duration = request.params.duration or 10
      local steps = request.params.steps or 5
      local actual_duration_ms = metadata.duration_ms
      local expected_duration_ms = duration * 1000
      
      -- Performance validation
      local duration_tolerance = 2000  -- 2 second tolerance
      local within_tolerance = math.abs(actual_duration_ms - expected_duration_ms) <= duration_tolerance
      
      -- Response validation
      local has_completion_message = false
      local has_timing_info = false
      
      if response and response[1] and response[1].text then
          local text = response[1].text
          has_completion_message = string.find(text:lower(), "completed") ~= nil
          has_timing_info = string.find(text, tostring(duration)) ~= nil or 
                           string.find(text, tostring(steps)) ~= nil
      end
      
      -- Calculate performance grade
      local performance_ratio = actual_duration_ms / expected_duration_ms
      local performance_grade = "A"
      
      if performance_ratio > 1.5 then
          performance_grade = "C"
      elseif performance_ratio > 1.2 then
          performance_grade = "B"
      end
      
      result = {
          success = within_tolerance and has_completion_message,
          message = string.format("Progress validation: %dms actual vs %dms expected (ratio: %.2f), Grade: %s", 
                                actual_duration_ms, expected_duration_ms, performance_ratio, performance_grade),
          performance_analysis = {
              expected_duration_ms = expected_duration_ms,
              actual_duration_ms = actual_duration_ms,
              within_tolerance = within_tolerance,
              performance_ratio = performance_ratio,
              performance_grade = performance_grade,
              has_completion_message = has_completion_message,
              has_timing_info = has_timing_info
          }
      }

  # Security and environment validation
  - name: "security_env_validator"
    language: "lua"
    execution_phase: "after"
    description: "Validates environment data for security compliance"
    required: true
    source: |
      local response = context.response
      
      if response and response[1] and response[1].text then
          local text = response[1].text
          
          -- Security checks - ensure no sensitive data is exposed
          local sensitive_patterns = {
              "password", "secret", "key", "token", "auth", 
              "private", "credential", "api_key", "access_key"
          }
          
          local security_violations = {}
          for _, pattern in ipairs(sensitive_patterns) do
              if string.find(text:lower(), pattern) then
                  table.insert(security_violations, pattern)
              end
          end
          
          -- Check for expected environment variables
          local has_node_env = string.find(text, "NODE_ENV") ~= nil
          local has_log_level = string.find(text, "LOG_LEVEL") ~= nil
          
          -- Validate JSON format (basic check)
          local looks_like_json = string.find(text, "{") and string.find(text, "}")
          
          -- Data size validation
          local data_size = string.len(text)
          local reasonable_size = data_size > 10 and data_size < 10000  -- Between 10 bytes and 10KB
          
          result = {
              success = #security_violations == 0 and has_node_env and reasonable_size,
              message = string.format("Security validation: %d violations, %d bytes, JSON: %s", 
                                    #security_violations, data_size, looks_like_json and "yes" or "no"),
              security_analysis = {
                  security_violations = security_violations,
                  violation_count = #security_violations,
                  has_expected_env_vars = has_node_env and has_log_level,
                  data_size_bytes = data_size,
                  reasonable_size = reasonable_size,
                  appears_json_formatted = looks_like_json
              }
          }
      else
          result = {
              success = false,
              message = "No environment data found in response"
          }
      end

# ==========================================
# COMPREHENSIVE TOOL TESTING (8 Tools)
# ==========================================

tools:
  # ----------------------------------------
  # Text Processing Tools
  # ----------------------------------------
  - name: "echo"
    description: "Simple echo tool to verify basic tool functionality"
    tests:
      - name: "basic_echo"
        description: "Test basic echo functionality with simple message"
        input:
          message: "Hello, MCP World!"
        expected:
          error: false
          fields:
            - path: "$[0].type"
              value: "text"
              required: true
            - path: "$[0].text"
              value: "Hello, MCP World!"
              required: true
        performance:
          max_duration_ms: 100
        tags: ["text", "basic", "echo"]

      - name: "echo_empty_message"
        description: "Test echo with empty message"
        input:
          message: ""
        expected:
          error: false
          fields:
            - path: "$[0].text"
              value: ""
              required: true
        tags: ["text", "edge-case", "empty"]

      - name: "echo_large_text"
        description: "Test echo with large text payload"
        input:
          message: "Large text payload for performance testing: This is a moderately sized text message designed to test how the echo tool handles larger payloads without overwhelming the system during testing."
        expected:
          error: false
          fields:
            - path: "$[0].text"
              field_type: "string"
              min_length: 100
              required: true
        performance:
          max_duration_ms: 200
        validation_scripts: ["large_text_analyzer"]
        tags: ["text", "performance", "large-payload"]

      - name: "echo_unicode_support" 
        description: "Test echo with Unicode characters"
        input:
          message: "🚀 Testing Unicode: 你好世界 🌍 Emoji support! 🎉"
        expected:
          error: false
          fields:
            - path: "$[0].text"
              contains: "🚀"
              required: true
        validation_scripts: ["unicode_validator"]
        tags: ["text", "unicode", "international"]

  # ----------------------------------------
  # Mathematical Tools
  # ----------------------------------------  
  - name: "add"
    description: "Mathematical addition tool for numeric operations"
    tests:
      - name: "integer_addition"
        description: "Test basic integer addition"
        input:
          a: 42
          b: 58
        expected:
          error: false
          fields:
            - path: "$[0].text"
              contains: "100"
              required: true
        performance:
          max_duration_ms: 50
        validation_scripts: ["math_precision_validator"]
        tags: ["math", "integer", "basic"]

      - name: "decimal_precision"
        description: "Test addition with decimal numbers"
        input:
          a: 3.14159
          b: 2.71828
        expected:
          error: false
          fields:
            - path: "$[0].text"
              field_type: "string"
              required: true
        validation_scripts: ["math_precision_validator"]
        tags: ["math", "decimal", "precision"]

      - name: "large_numbers"
        description: "Test addition with large numbers"
        input:
          a: 9007199254740991  # JavaScript MAX_SAFE_INTEGER
          b: 1
        expected:
          error: false
          fields:
            - path: "$[0].text"
              field_type: "string"
              required: true
        validation_scripts: ["math_precision_validator"]
        tags: ["math", "large-numbers", "limits"]

      - name: "negative_numbers"
        description: "Test addition with negative numbers"
        input:
          a: -50
          b: 30
        expected:
          error: false
          fields:
            - path: "$[0].text"
              contains: "-20"
              required: true
        validation_scripts: ["math_precision_validator"]
        tags: ["math", "negative", "edge-case"]

      - name: "add_missing_parameter"
        description: "Test error handling when parameter is missing"
        input:
          a: 10
          # Missing 'b' parameter
        expected:
          error: true
          error_code: -32602
          error_message_contains: "Invalid params"
        tags: ["math", "error", "validation"]

  # ----------------------------------------
  # Progress & Timing Tools
  # ----------------------------------------
  - name: "longRunningOperation"
    description: "Tool demonstrating progress notifications and long operations"
    tests:
      - name: "default_operation"
        description: "Test default long-running operation (10 seconds, 5 steps)"
        input: {}
        expected:
          error: false
          fields:
            - path: "$[0].text"
              contains: "completed"
              required: true
        performance:
          max_duration_ms: 12000  # Allow extra time for 10-second operation
          expect_progress_notifications: true
        validation_scripts: ["progress_performance_validator"]
        tags: ["progress", "default", "timing"]

      - name: "custom_duration"
        description: "Test custom duration operation"
        input:
          duration: 3
          steps: 3
        expected:
          error: false
          fields:
            - path: "$[0].text"
              contains: "3 seconds"
              required: true
        performance:
          max_duration_ms: 5000
          expect_progress_notifications: true
        validation_scripts: ["progress_performance_validator"]
        tags: ["progress", "custom", "timing"]

      - name: "progress_notifications"
        description: "Verify progress notifications are sent during operation"
        input:
          duration: 2
          steps: 4
        expected:
          error: false
          progress_expected: true
          min_progress_updates: 3
        performance:
          max_duration_ms: 4000
        tags: ["progress", "notifications", "realtime"]

      - name: "zero_duration_edge_case"
        description: "Test operation with zero duration"
        input:
          duration: 0
          steps: 1
        expected:
          error: false
          fields:
            - path: "$[0].text"
              field_type: "string"
              required: true
        performance:
          max_duration_ms: 1000
        tags: ["progress", "edge-case", "zero"]

  # ----------------------------------------
  # LLM Integration Tools - DISABLED
  # ----------------------------------------
  # Note: sampleLLM tool disabled because server returns MCP error -32601 (method not found)
  # The server does not currently support sampling/createMessage functionality
  # Uncomment when server adds sampling support
  # sampleLLM tool removed - server returns MCP error -32601 (method not found)
  # The server does not currently support sampling/createMessage functionality

  # ----------------------------------------
  # Media Tools
  # ----------------------------------------
  - name: "getTinyImage"
    description: "Tool returning a small test image in base64 format"
    tests:
      - name: "image_generation"
        description: "Test basic image generation"
        input: {}
        expected:
          error: false
          fields:
            - path: "$[0].type"
              value: "image"
              required: true
            - path: "$[0].data"
              field_type: "string"
              pattern: "^data:image/png;base64,"
              required: true
        performance:
          max_duration_ms: 500
        validation_scripts: ["base64_image_validator"]
        tags: ["media", "image", "base64"]

      - name: "base64_validation"
        description: "Validate base64 encoding of returned image"
        input: {}
        expected:
          error: false
          fields:
            - path: "$[0].data"
              field_type: "string"
              min_length: 100  # Base64 encoded PNG should be substantial
              required: true
        validation_scripts: ["base64_image_validator"]
        tags: ["media", "validation", "encoding"]

      - name: "image_format_verification"
        description: "Verify PNG format in image data"
        input: {}
        expected:
          error: false
          fields:
            - path: "$[0].data"
              contains: "iVBORw0KGgo"  # PNG header in base64
              required: true
        validation_scripts: ["base64_image_validator"]
        tags: ["media", "format", "png"]

  # ----------------------------------------  
  # System Tools
  # ----------------------------------------
  - name: "printEnv"
    description: "Tool that prints environment variables for debugging"
    tests:
      - name: "env_access"
        description: "Test basic environment variable access"
        input: {}
        expected:
          error: false
          fields:
            - path: "$[0].text"
              field_type: "string"
              min_length: 10
              required: true
        performance:
          max_duration_ms: 200
        validation_scripts: ["security_env_validator"]
        tags: ["system", "environment", "debug"]

      - name: "env_data_format"
        description: "Verify environment data is in JSON format"
        input: {}
        expected:
          error: false
          fields:
            - path: "$[0].text"
              contains: "NODE_ENV"
              required: true
        validation_scripts: ["security_env_validator"]
        tags: ["system", "json", "format"]

      - name: "security_validation"
        description: "Ensure no sensitive data is exposed"
        input: {}
        expected:
          error: false
          # Note: Should not contain actual sensitive environment variables
          security_constraints:
            - constraint_type: "no_passwords"
              enabled: true
            - constraint_type: "no_api_keys"
              enabled: true
        validation_scripts: ["security_env_validator"]
        tags: ["system", "security", "validation"]

  # ----------------------------------------
  # Annotation Tools  
  # ----------------------------------------
  - name: "annotatedMessage"
    description: "Tool demonstrating MCP annotation system with metadata"
    tests:
      - name: "error_annotations"
        description: "Test error message with high priority annotations"
        input:
          messageType: "error"
          includeImage: false
        expected:
          error: false
          fields:
            - path: "$[0].annotations.priority"
              value: 1.0
              required: true
            - path: "$[0].annotations.audience"
              contains: "user"
              required: true
            - path: "$[0].annotations.audience"
              contains: "assistant"
              required: true
        tags: ["annotations", "error", "priority"]

      - name: "success_annotations"
        description: "Test success message with medium priority annotations"
        input:
          messageType: "success"
          includeImage: false
        expected:
          error: false
          fields:
            - path: "$[0].annotations.priority"
              value: 0.7
              required: true
            - path: "$[0].annotations.audience"
              contains: "user"
              required: true
        tags: ["annotations", "success", "priority"]

      - name: "debug_annotations"
        description: "Test debug message with low priority annotations"
        input:
          messageType: "debug"
          includeImage: false
        expected:
          error: false
          fields:
            - path: "$[0].annotations.priority"
              value: 0.3
              required: true
            - path: "$[0].annotations.audience"
              contains: "assistant"
              required: true
        tags: ["annotations", "debug", "priority"]

      - name: "image_inclusion"
        description: "Test message with image inclusion"
        input:
          messageType: "success"
          includeImage: true
        expected:
          error: false
          fields:
            - path: "$[1].type"
              value: "image"
              required: true
            - path: "$[1].annotations.priority"
              value: 0.5
              required: true
        tags: ["annotations", "image", "media"]

      - name: "invalid_message_type"
        description: "Test error handling with invalid message type"
        input:
          messageType: "invalid"
          includeImage: false
        expected:
          error: true
          error_message_contains: "messageType"
        tags: ["annotations", "error", "validation"]

  # ----------------------------------------
  # Resource Integration Tools
  # ----------------------------------------  
  - name: "getResourceReference"
    description: "Tool that returns resource references for MCP client usage"
    tests:
      - name: "valid_resource_reference"
        description: "Test valid resource reference generation"
        input:
          resourceId: 42
        expected:
          error: false
          fields:
            - path: "$[1].type"
              value: "resource"
              required: true
            - path: "$[1].resource.uri"
              value: "test://static/resource/42"
              required: true
        performance:
          max_duration_ms: 200
        tags: ["resources", "reference", "uri"]

      - name: "boundary_resource_ids"
        description: "Test boundary resource IDs (1 and 100)"
        input:
          resourceId: 1
        expected:
          error: false
          fields:
            - path: "$[1].resource.uri"
              value: "test://static/resource/1"
              required: true
        tags: ["resources", "boundary", "edge-case"]

      - name: "max_resource_id"
        description: "Test maximum valid resource ID"
        input:
          resourceId: 100
        expected:
          error: false
          fields:
            - path: "$[1].resource.uri"
              value: "test://static/resource/100"
              required: true
        tags: ["resources", "boundary", "maximum"]

      - name: "invalid_resource_id_low"
        description: "Test error with resource ID below range"
        input:
          resourceId: 0
        expected:
          error: true
          error_code: -32603
          error_message_contains: "Number must be greater than or equal to 1"
        tags: ["resources", "error", "validation"]

      - name: "invalid_resource_id_high"
        description: "Test error with resource ID above range"
        input:
          resourceId: 101
        expected:
          error: true
          error_code: -32602
          error_message_contains: "resourceId must be between 1 and 100"
        tags: ["resources", "error", "validation"]

# ==========================================
# RESOURCE SYSTEM TESTING (100 Resources)
# ==========================================

resources:
  - uri_template: "test://static/resource/{id}"
    name: "Everything Server Test Resources"
    description: "100 test resources demonstrating pagination and subscriptions"
    mime_type: "text/plain"
    tests:
      - name: "resource_list_first_page"
        description: "Test first page of resources (pagination)"
        input:
          cursor: null
        expected:
          error: false
          fields:
            - path: "$.resources"
              field_type: "array"
              array_length: 10  # Default page size
              required: true
            - path: "$.nextCursor"
              field_type: "string"
              required: true
        performance:
          max_duration_ms: 500
        tags: ["resources", "pagination", "list"]

      - name: "resource_list_second_page"
        description: "Test pagination with cursor"
        input:
          cursor: "page2"
        expected:
          error: false
          fields:
            - path: "$.resources"
              field_type: "array"
              min_length: 1
              required: true
        tags: ["resources", "pagination", "cursor"]

      - name: "read_even_numbered_resource"
        description: "Test reading even-numbered resource (plaintext)"
        input:
          uri: "test://static/resource/2"
        expected:
          error: false
          fields:
            - path: "$.contents[0].mimeType"
              value: "text/plain"
              required: true
            - path: "$.contents[0].text"
              field_type: "string"
              contains: "Resource 2"
              required: true
        tags: ["resources", "read", "plaintext", "even"]

      - name: "read_odd_numbered_resource"
        description: "Test reading odd-numbered resource (binary blob)"
        input:
          uri: "test://static/resource/3"
        expected:
          error: false
          fields:
            - path: "$.contents[0].mimeType"
              value: "application/octet-stream"
              required: true
            - path: "$.contents[0].blob"
              field_type: "string"  # Base64 encoded binary
              pattern: "^[A-Za-z0-9+/]+=*$"
              required: true
        tags: ["resources", "read", "binary", "odd"]

      - name: "resource_subscription_test"
        description: "Test resource subscription and updates"
        input:
          uri: "test://static/resource/1"
          subscribe: true
        expected:
          error: false
          subscription_expected: true
          update_interval_seconds: 5
        tags: ["resources", "subscription", "realtime"]

      - name: "resource_not_found"
        description: "Test error handling for non-existent resource"
        input:
          uri: "test://static/resource/101"
        expected:
          error: true
          error_code: -32602
          error_message_contains: "Resource not found"
        tags: ["resources", "error", "not-found"]

      - name: "invalid_resource_uri"
        description: "Test error handling for malformed URI"
        input:
          uri: "invalid://malformed/uri"
        expected:
          error: true
          error_code: -32602
          error_message_contains: "Invalid URI"
        tags: ["resources", "error", "validation"]

      - name: "large_resource_set_performance"
        description: "Test performance with large resource listing"
        input:
          limit: 100  # Request all resources
        expected:
          error: false
          fields:
            - path: "$.resources"
              field_type: "array"
              min_length: 90  # Should get most/all resources
              required: true
        performance:
          max_duration_ms: 2000
        tags: ["resources", "performance", "large-set"]

# ==========================================
# PROMPT TEMPLATE SYSTEM (3 Prompts)
# ==========================================

# prompts: # DISABLED - Server does not fully support prompts functionality  
# - name: "simple_prompt"
    # description: "Basic prompt without arguments"
    # tests:
    #   - name: "no_arguments_required"
    #     description: "Test simple prompt with no arguments"
    #     input: {}
    #     expected:
    #       error: false
    #       fields:
    #         - path: "$.messages"
    #           field_type: "array"
    #           min_length: 1
    #           required: true
    #         - path: "$.messages[0].role"
    #           value: "user"
    #           required: true
    #     performance:
    #       max_duration_ms: 500
    #     tags: ["prompts", "simple", "no-args"]

    #   - name: "response_format_validation"
    #     description: "Validate prompt response format"
    #     input: {}
    #     expected:
    #       error: false
    #       fields:
    #         - path: "$.messages[0].content"
    #           field_type: "string"
    #           min_length: 10
    #           required: true
    #     tags: ["prompts", "format", "validation"]

  - name: "complex_prompt"
    description: "Advanced prompt with required and optional arguments"
    tests:
      - name: "required_arguments_only"
        description: "Test prompt with only required arguments"
        input:
          temperature: 0.7
        expected:
          error: false
          fields:
            - path: "$.messages"
              field_type: "array"
              min_length: 1
              required: true
        tags: ["prompts", "complex", "required"]

      - name: "all_arguments_provided"
        description: "Test prompt with all arguments"
        input:
          temperature: 0.8
          style: "creative"
        expected:
          error: false
          fields:
            - path: "$.messages"
              field_type: "array"
              min_length: 2  # Should include more content with style
              required: true
        tags: ["prompts", "complex", "all-args"]

      - name: "invalid_temperature_range"
        description: "Test error with temperature out of range"
        input:
          temperature: 2.0  # Invalid - should be 0-1
        expected:
          error: true
          error_code: -32602
          error_message_contains: "temperature"
        tags: ["prompts", "error", "validation"]

      - name: "missing_required_argument"
        description: "Test error when required argument is missing"
        input:
          style: "formal"
          # Missing temperature
        expected:
          error: true
          error_code: -32602
          error_message_contains: "temperature"
        tags: ["prompts", "error", "required"]

      - name: "style_variations"
        description: "Test different style options"
        input:
          temperature: 0.5
          style: "formal"
        expected:
          error: false
          fields:
            - path: "$.messages[0].content"
              contains: "formal"
              required: true
        tags: ["prompts", "style", "variation"]

  - name: "resource_prompt"
    description: "Prompt that embeds resource references"
    tests:
      - name: "valid_resource_embedding"
        description: "Test prompt with valid resource embedding"
        input:
          resourceId: 25
        expected:
          error: false
          fields:
            - path: "$.messages"
              field_type: "array"
              min_length: 1
              required: true
            - path: "$.messages[0].content.type"
              value: "resource"
              required: true
        tags: ["prompts", "resources", "embedding"]

      - name: "resource_content_inclusion"
        description: "Verify resource content is included in prompt"
        input:
          resourceId: 50
        expected:
          error: false
          fields:
            - path: "$.messages[0].content.resource.uri"
              value: "test://static/resource/50"
              required: true
        tags: ["prompts", "resources", "content"]

      - name: "invalid_resource_id_in_prompt"
        description: "Test error with invalid resource ID"
        input:
          resourceId: 200
        expected:
          error: true
          error_code: -32602
          error_message_contains: "resourceId must be between 1 and 100"
        tags: ["prompts", "error", "validation"]

# ==========================================
# ADVANCED PROTOCOL FEATURES
# ==========================================

# Test configuration for advanced features
test_config:
  timeout_seconds: 60
  max_concurrency: 5
  fail_fast: false
  retry:
    max_retries: 2
    retry_delay_ms: 1000
    exponential_backoff: true
  
  # Progress notification testing
  progress_notifications:
    enabled: true
    timeout_seconds: 30
    min_updates_expected: 2
  
  # Logging testing
  logging_tests:
    enabled: true
    log_collection_duration_seconds: 20
    expected_log_levels: ["info", "warn", "error", "debug"]
    min_log_messages_expected: 1
  
  # Subscription testing
  subscription_tests:
    enabled: true
    update_timeout_seconds: 10
    min_updates_expected: 1
  
  # Transport protocol testing
  transport_tests:
    stdio: 
      enabled: true
      startup_timeout: 30
    sse:
      enabled: false  # Can be enabled for full transport testing
      url: "http://localhost:3000/sse"
    http:
      enabled: false  # Can be enabled for full transport testing  
      url: "http://localhost:3000/mcp"

# Metadata for comprehensive testing
metadata:
  author: "MCP Test Harness Team"
  documentation: "https://spec.modelcontextprotocol.io/"
  license: "MIT"
  tags: ["reference", "comprehensive", "everything", "sampling", "experimental"]
  test_coverage:
    tools: 8
    resources: 100  
    prompts: 3
    scenarios: 45+
    capabilities: ["tools", "resources", "prompts", "sampling", "logging"]
  
  # Performance benchmarks
  benchmarks:
    tool_response_time_ms: 100
    resource_access_time_ms: 200
    prompt_generation_time_ms: 1000
    llm_sampling_time_ms: 30000
    long_operation_time_ms: 12000
  
  # Quality metrics
  quality_targets:
    success_rate_percent: 95
    error_handling_coverage_percent: 100
    performance_test_coverage_percent: 80
    security_test_coverage_percent: 90 